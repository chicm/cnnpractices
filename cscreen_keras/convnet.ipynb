{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chicm/ml/cnnpractices/cervc/data/crop'\n",
    "TRAIN_DIR = DATA_DIR+'/train'\n",
    "TEST_DIR = DATA_DIR + '/test'\n",
    "VAL_DIR = DATA_DIR + '/valid'\n",
    "RESULT_DIR = DATA_DIR + '/results'\n",
    "\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_conv_layers(input_shape):\n",
    "    return [\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(axis=-1),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(256, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(256, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=-1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dropout(0.25),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(3, activation='softmax')\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 220, 220, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 220, 220, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 108, 108, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 106, 106, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 106, 106, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 51, 51, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 51, 51, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 49, 49, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 49, 49, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,718,435.0\n",
      "Trainable params: 1,716,003.0\n",
      "Non-trainable params: 2,432.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = Sequential(get_conv_layers(input_shape))\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7024 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30, \n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.05, \n",
    "        shear_range=0.1,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7024\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.samples)\n",
    "print(len(model.layers))\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch):\n",
    "    if epoch <= 10:\n",
    "        return 0.01\n",
    "    elif epoch <= 50: \n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "45s - loss: 1.1284 - acc: 0.4603 - val_loss: 1.0547 - val_acc: 0.4497\n",
      "Epoch 2/300\n",
      "46s - loss: 1.0265 - acc: 0.4867 - val_loss: 1.0206 - val_acc: 0.4472\n",
      "Epoch 3/300\n",
      "45s - loss: 0.9990 - acc: 0.4956 - val_loss: 0.9933 - val_acc: 0.5282\n",
      "Epoch 4/300\n",
      "46s - loss: 0.9811 - acc: 0.5060 - val_loss: 0.9735 - val_acc: 0.5423\n",
      "Epoch 5/300\n",
      "49s - loss: 0.9782 - acc: 0.5030 - val_loss: 0.9566 - val_acc: 0.4771\n",
      "Epoch 6/300\n",
      "46s - loss: 0.9721 - acc: 0.5061 - val_loss: 1.0904 - val_acc: 0.4613\n",
      "Epoch 7/300\n",
      "44s - loss: 0.9711 - acc: 0.4980 - val_loss: 1.0370 - val_acc: 0.5211\n",
      "Epoch 8/300\n",
      "44s - loss: 0.9730 - acc: 0.5047 - val_loss: 0.9975 - val_acc: 0.5106\n",
      "Epoch 9/300\n",
      "44s - loss: 0.9648 - acc: 0.5111 - val_loss: 1.0349 - val_acc: 0.4542\n",
      "Epoch 10/300\n",
      "44s - loss: 0.9666 - acc: 0.5091 - val_loss: 0.9496 - val_acc: 0.5194\n",
      "Epoch 11/300\n",
      "45s - loss: 0.9674 - acc: 0.5081 - val_loss: 0.9509 - val_acc: 0.5387\n",
      "Epoch 12/300\n",
      "47s - loss: 0.9480 - acc: 0.5121 - val_loss: 0.9193 - val_acc: 0.5440\n",
      "Epoch 13/300\n",
      "46s - loss: 0.9436 - acc: 0.5194 - val_loss: 0.9588 - val_acc: 0.5229\n",
      "Epoch 14/300\n",
      "47s - loss: 0.9413 - acc: 0.5198 - val_loss: 0.9364 - val_acc: 0.5141\n",
      "Epoch 15/300\n",
      "47s - loss: 0.9378 - acc: 0.5195 - val_loss: 0.9392 - val_acc: 0.5352\n",
      "Epoch 16/300\n",
      "45s - loss: 0.9411 - acc: 0.5187 - val_loss: 0.9434 - val_acc: 0.5229\n",
      "Epoch 17/300\n",
      "46s - loss: 0.9396 - acc: 0.5203 - val_loss: 0.8890 - val_acc: 0.5739\n",
      "Epoch 18/300\n",
      "47s - loss: 0.9367 - acc: 0.5193 - val_loss: 0.9157 - val_acc: 0.5563\n",
      "Epoch 19/300\n",
      "45s - loss: 0.9369 - acc: 0.5235 - val_loss: 0.9283 - val_acc: 0.5070\n",
      "Epoch 20/300\n",
      "44s - loss: 0.9380 - acc: 0.5210 - val_loss: 0.9171 - val_acc: 0.5260\n",
      "Epoch 21/300\n",
      "44s - loss: 0.9294 - acc: 0.5320 - val_loss: 0.9180 - val_acc: 0.5669\n",
      "Epoch 22/300\n",
      "45s - loss: 0.9339 - acc: 0.5218 - val_loss: 0.9186 - val_acc: 0.5775\n",
      "Epoch 23/300\n",
      "45s - loss: 0.9361 - acc: 0.5243 - val_loss: 0.9101 - val_acc: 0.5475\n",
      "Epoch 24/300\n",
      "46s - loss: 0.9239 - acc: 0.5304 - val_loss: 0.9091 - val_acc: 0.5528\n",
      "Epoch 25/300\n",
      "44s - loss: 0.9310 - acc: 0.5245 - val_loss: 0.9270 - val_acc: 0.5335\n",
      "Epoch 26/300\n",
      "45s - loss: 0.9332 - acc: 0.5213 - val_loss: 0.9345 - val_acc: 0.5370\n",
      "Epoch 27/300\n",
      "46s - loss: 0.9295 - acc: 0.5241 - val_loss: 0.9131 - val_acc: 0.5440\n",
      "Epoch 28/300\n",
      "45s - loss: 0.9272 - acc: 0.5163 - val_loss: 0.9015 - val_acc: 0.5475\n",
      "Epoch 29/300\n",
      "45s - loss: 0.9352 - acc: 0.5190 - val_loss: 0.9259 - val_acc: 0.5651\n",
      "Epoch 30/300\n",
      "45s - loss: 0.9263 - acc: 0.5218 - val_loss: 0.9006 - val_acc: 0.5511\n",
      "Epoch 31/300\n",
      "45s - loss: 0.9255 - acc: 0.5261 - val_loss: 0.9045 - val_acc: 0.4912\n",
      "Epoch 32/300\n",
      "46s - loss: 0.9162 - acc: 0.5250 - val_loss: 0.8826 - val_acc: 0.5616\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-02affbd8c21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     callbacks=[ModelCheckpoint(w_file, monitor='val_acc', save_best_only=True),\n\u001b[0;32m---> 14\u001b[0;31m               LearningRateScheduler(lr_schedule)]\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chicm/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "w_file = RESULT_DIR + '/conv_1.h5'\n",
    "\n",
    "#model.load_weights(RESULT_DIR + '/res_1.h5')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    verbose=2,\n",
    "    callbacks=[ModelCheckpoint(w_file, monitor='val_acc', save_best_only=True),\n",
    "              LearningRateScheduler(lr_schedule)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Type_1': 0, 'Type_2': 1, 'Type_3': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(w_file)\n",
    "preds1 = model.predict_generator(test_generator, steps = test_generator.samples // batch_size)\n",
    "print(preds1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "w_file2 = RESULT_DIR + '/res_1.h5'\n",
    "model.load_weights(w_file2)\n",
    "preds2 = model.predict(test_images)\n",
    "print(preds2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "preds = np.mean([preds1, preds2], axis=0)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.41162463e-04   9.99011397e-01   4.74229528e-05]\n",
      " [  7.16020539e-03   8.88448358e-01   1.04391396e-01]\n",
      " [  7.55762756e-02   6.26130223e-01   2.98293501e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): \n",
    "    return np.clip(arr, (1-mx)/2, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds, 0.83)\n",
    "subm_name = RESULT_DIR+'/sub1.csv' \n",
    "\n",
    "classes = sorted(train_generator.class_indices, key=train_generator.class_indices.get)\n",
    "print(classes)\n",
    "\n",
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "\n",
    "submission.insert(0, 'image_name', [a[8:] for a in test_generator.filenames])\n",
    "    #print [a for a in batches.filenames][:10]\n",
    "print(submission.head())\n",
    "submission.to_csv(subm_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds, 0.83)\n",
    "sample_submission = pd.read_csv(\"/home/chicm/ml/cnnpractices/cervc/data/sample_submission.csv\")\n",
    "\n",
    "#for i, name in enumerate(test_filenames):\n",
    "#    f_name = name.split('/')[1]\n",
    "#    sample_submission.loc[sample_submission['image_name'] == f_name, 'Type_1'] = subm[i][0]\n",
    "#    sample_submission.loc[sample_submission['image_name'] == f_name, 'Type_2'] = subm[i][1]\n",
    "#    sample_submission.loc[sample_submission['image_name'] == f_name, 'Type_3'] = subm[i][2]\n",
    "sample_submission['Type_1'] = subm[:, 0]\n",
    "sample_submission['Type_2'] = subm[:, 1]\n",
    "sample_submission['Type_3'] = subm[:, 2]\n",
    "sample_submission['image_name'] = fnames\n",
    "\n",
    "sample_submission.to_csv(RESULT_DIR+\"/submit1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.085       0.82999998  0.085     ]\n",
      " [ 0.085       0.82999998  0.1043914 ]\n",
      " [ 0.085       0.62613022  0.2982935 ]\n",
      " [ 0.085       0.085       0.82999998]\n",
      " [ 0.085       0.21464032  0.78290635]]\n"
     ]
    }
   ],
   "source": [
    "print(subm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_name    Type_1    Type_2    Type_3\n",
      "0       17.jpg  0.085000  0.830000  0.085000\n",
      "1      416.jpg  0.085000  0.830000  0.104391\n",
      "2      372.jpg  0.085000  0.626130  0.298294\n",
      "3       44.jpg  0.085000  0.085000  0.830000\n",
      "4       94.jpg  0.085000  0.214640  0.782906\n",
      "5       35.jpg  0.085000  0.085000  0.830000\n",
      "6      381.jpg  0.085000  0.716729  0.255482\n",
      "7       42.jpg  0.085000  0.830000  0.085000\n",
      "8      482.jpg  0.566722  0.085000  0.433181\n",
      "9      178.jpg  0.085000  0.085000  0.830000\n",
      "10      99.jpg  0.085000  0.556539  0.427407\n",
      "11     241.jpg  0.085000  0.085000  0.830000\n",
      "12      52.jpg  0.085000  0.085000  0.830000\n",
      "13     165.jpg  0.085000  0.764459  0.218825\n",
      "14     355.jpg  0.830000  0.085000  0.085000\n",
      "15     345.jpg  0.085000  0.830000  0.085000\n",
      "16     365.jpg  0.085000  0.830000  0.085000\n",
      "17     306.jpg  0.085000  0.830000  0.085000\n",
      "18     395.jpg  0.085000  0.830000  0.085000\n",
      "19     393.jpg  0.085000  0.085000  0.830000\n",
      "20     118.jpg  0.085000  0.085000  0.830000\n",
      "21      39.jpg  0.114935  0.150578  0.734487\n",
      "22     378.jpg  0.095382  0.830000  0.085000\n",
      "23      74.jpg  0.085000  0.085000  0.830000\n",
      "24      72.jpg  0.085000  0.296377  0.702440\n",
      "25     479.jpg  0.085000  0.296034  0.703603\n",
      "26     350.jpg  0.085000  0.343071  0.641768\n",
      "27     271.jpg  0.085000  0.830000  0.113203\n",
      "28     347.jpg  0.085000  0.830000  0.085000\n",
      "29     217.jpg  0.085000  0.830000  0.085000\n",
      "..         ...       ...       ...       ...\n",
      "482    212.jpg  0.085000  0.426659  0.572957\n",
      "483     88.jpg  0.094250  0.325600  0.580149\n",
      "484    223.jpg  0.085000  0.085000  0.830000\n",
      "485    133.jpg  0.085000  0.085000  0.830000\n",
      "486    424.jpg  0.085000  0.830000  0.085000\n",
      "487    119.jpg  0.085000  0.085000  0.830000\n",
      "488    148.jpg  0.085000  0.830000  0.085000\n",
      "489    476.jpg  0.085000  0.830000  0.085000\n",
      "490    445.jpg  0.085000  0.085000  0.830000\n",
      "491    495.jpg  0.085000  0.830000  0.085000\n",
      "492    141.jpg  0.085000  0.085000  0.830000\n",
      "493    263.jpg  0.085000  0.728924  0.270979\n",
      "494    330.jpg  0.085000  0.585852  0.413363\n",
      "495    186.jpg  0.085000  0.583639  0.414731\n",
      "496    252.jpg  0.085000  0.830000  0.085000\n",
      "497    132.jpg  0.085000  0.085000  0.830000\n",
      "498    499.jpg  0.085000  0.085000  0.830000\n",
      "499    348.jpg  0.085000  0.356899  0.620866\n",
      "500    142.jpg  0.315088  0.447681  0.237231\n",
      "501    316.jpg  0.085000  0.830000  0.085000\n",
      "502    502.jpg  0.085000  0.085000  0.830000\n",
      "503    357.jpg  0.085000  0.471418  0.517899\n",
      "504     36.jpg  0.085000  0.830000  0.085000\n",
      "505    435.jpg  0.085000  0.085000  0.830000\n",
      "506    196.jpg  0.085000  0.387136  0.548789\n",
      "507    422.jpg  0.085000  0.527533  0.471590\n",
      "508     20.jpg  0.085000  0.085000  0.830000\n",
      "509    501.jpg  0.085000  0.830000  0.085000\n",
      "510    129.jpg  0.085000  0.830000  0.085000\n",
      "511     31.jpg  0.085000  0.830000  0.085000\n",
      "\n",
      "[512 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
